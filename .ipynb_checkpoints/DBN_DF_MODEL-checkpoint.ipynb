{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.regression import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from dbn.tensorflow import SupervisedDBNRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training dataset for pm1 & pm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBM_EPOCHS = 5\n",
    "DBN_EPOCHS = 10\n",
    "RBM_LEARNING_RATE = 0.01\n",
    "DBN_LEARNING_RATE = 0.01\n",
    "HIDDEN_LAYER_STRUCT = [25, 50, 100]\n",
    "ACTIVE_FUNC = 'relu'\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "ROAD = \"Taft Ave.\"\n",
    "YEAR = \"2015\"\n",
    "EXT = \".csv\"\n",
    "FILENAME = \"merged_mmda_wwo_\" + ROAD + \"_\" + YEAR\n",
    "original_dataset = pd.read_csv(\"data/mmda-wwo/\" + FILENAME + EXT, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_dataset = original_dataset\n",
    "# Preparing Traffic Dataset\n",
    "# Remove date time. Remove unused columms\n",
    "#0-2 = dt + lineName + stationName || 3-4 - statusN - statusS || 5-end - weather variables\n",
    "cols_to_remove = [0, 1, 2] + list(range(5, traffic_dataset.shape[1]))\n",
    "\n",
    "traffic_dataset = traffic_dataset.drop(traffic_dataset.columns[[cols_to_remove]], axis=1)\n",
    "#traffic_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dataset = original_dataset\n",
    "# Remove date time. Remove unused columms\n",
    "#0-2 = dt + lineName + stationName || 3-4 - statusN - statusS || 5-end - weather variables\n",
    "cols_to_remove = [0, 1, 2] + [3, 4]\n",
    "\n",
    "#Remove Redundant Variables\n",
    "#Variables = tempC WindspeedKmph, cond, precipMM, humidity, visibility, pressure, cloudcover, dewPointC, windGustKmph, \n",
    "redundant_variables = [6, 7, 9, 16, 17, 19, 20, 21, 22, 24, 25]\n",
    "cols_to_remove += redundant_variables\n",
    "\n",
    "weather_dataset = weather_dataset.drop(weather_dataset.columns[[cols_to_remove]], axis=1)\n",
    "#weather_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Training PM1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset for PM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-be Predicted variable\n",
    "Y = original_dataset.statusS\n",
    "Y = Y.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other data\n",
    "X = traffic_dataset\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.67, shuffle=False)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Data scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training PM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.095327\n"
     ]
    }
   ],
   "source": [
    "pm1 = SupervisedDBNRegression(hidden_layers_structure=HIDDEN_LAYER_STRUCT,\n",
    "                                    learning_rate_rbm=RBM_LEARNING_RATE,\n",
    "                                    learning_rate=DBN_LEARNING_RATE,\n",
    "                                    n_epochs_rbm=RBM_EPOCHS,\n",
    "                                    n_iter_backprop=DBN_EPOCHS,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    activation_function=ACTIVE_FUNC)\n",
    "pm1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing PM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "Y_pred = pm1.predict(X_test)\n",
    "print('Done.\\nR-squared: %f\\nMSE: %f' % (r2_score(Y_test, Y_pred), mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Results\n",
    "temp = []\n",
    "for i in range(len(Y_pred)):\n",
    "    temp.append(Y_pred[i][0])\n",
    "d = {'Predicted': temp, 'Actual': Y_test}\n",
    "pm1_results = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Results into csv file\n",
    "pm1_results.to_csv(\"output/pm1_output_\" + ROAD + \"_\" + YEAR + EXT, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Training PM2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset for PM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other data\n",
    "X = weather_dataset\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.67, shuffle=False)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Data scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training PM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2 = SupervisedDBNRegression(hidden_layers_structure=HIDDEN_LAYER_STRUCT,\n",
    "                                    learning_rate_rbm=RBM_LEARNING_RATE,\n",
    "                                    learning_rate=DBN_LEARNING_RATE,\n",
    "                                    n_epochs_rbm=RBM_EPOCHS,\n",
    "                                    n_iter_backprop=DBN_EPOCHS,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    activation_function=ACTIVE_FUNC)\n",
    "pm2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing PM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = min_max_scaler.transform(X_test)\n",
    "Y_pred = pm2.predict(X_test)\n",
    "print('Done.\\nR-squared: %f\\nMSE: %f' % (r2_score(Y_test, Y_pred), mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Results\n",
    "temp = []\n",
    "for i in range(len(Y_pred)):\n",
    "    temp.append(Y_pred[i][0])\n",
    "d = {'Predicted': temp, 'Actual': Y_test}\n",
    "pm2_results = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Results into csv file\n",
    "pm2_results.to_csv(\"output/pm2_output_\" + ROAD + \"_\" + YEAR + EXT, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Fusion Center\n",
    "### Preparing Training Dataset for Fusion Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'PM1-Output': pm1_results.Predicted, 'PM2-Output': pm2_results.Predicted}\n",
    "fusion_dataset = pd.DataFrame(data=d)\n",
    "fusion_dataset = np.array(fusion_dataset)\n",
    "actual_dataset = pm1_results.Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-be Predicted variable\n",
    "Y = actual_dataset\n",
    "Y = Y.round(5)\n",
    "\n",
    "# Other data\n",
    "X = fusion_dataset\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.67, shuffle=False)\n",
    "X_train = np.array(X_train) q\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Data scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Fusion Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "fc = SupervisedDBNRegression(hidden_layers_structure=HIDDEN_LAYER_STRUCT,\n",
    "                                    learning_rate_rbm=RBM_LEARNING_RATE,\n",
    "                                    learning_rate=DBN_LEARNING_RATE,\n",
    "                                    n_epochs_rbm=RBM_EPOCHS,\n",
    "                                    n_iter_backprop=DBN_EPOCHS,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    activation_function=ACTIVE_FUNC)\n",
    "fc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Fusion Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "Y_pred = fc.predict(X_test)\n",
    "print('Done.\\nR-squared: %f\\nMSE: %f' % (r2_score(Y_test, Y_pred), mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in range(len(Y_pred)):\n",
    "    temp.append(Y_pred[i][0])\n",
    "d = {'Predicted': temp, 'Actual': Y_test}\n",
    "fc_results = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_results.to_csv(\"output/fc_output_\" + ROAD  + \"_\" + YEAR + EXT, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "pm1.save('models/pm1_' + ROAD + '_' + YEAR +'.pkl')\n",
    "pm2.save('models/pm2_' + ROAD + '_' + YEAR + '.pkl')\n",
    "fc.save('models/fc_' + ROAD + '_' + YEAR + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
